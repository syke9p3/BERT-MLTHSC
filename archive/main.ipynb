{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BERT Model'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"BERT Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Repo\\Thesis\\BERT-MLTHSC\\main.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repo/Thesis/BERT-MLTHSC/main.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repo/Thesis/BERT-MLTHSC/main.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repo/Thesis/BERT-MLTHSC/main.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoModel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AdamW, get_cosine_schedule_with_warmup\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at gklmip/bert-tagalog-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gklmip/bert-tagalog-base-uncased\"\n",
    "BERT_MODEL = AutoModel.from_pretrained(model_name, return_dict=True)\n",
    "BERT_TOKENIZER = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './dataset/train-try.csv'\n",
    "val_path = './dataset/val.csv'\n",
    "test_path = './dataset/test-try.csv'\n",
    "dataset_path = './dataset/mlthsc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path)\n",
    "train_df = pd.read_csv(train_path)\n",
    "val_df = pd.read_csv(val_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "LABELS = ['Age', 'Gender', 'Physical', 'Race', 'Religion', 'Others']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repo\\Thesis\\BERT-MLTHSC\\main.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repo/Thesis/BERT-MLTHSC/main.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLTHSDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data: pd.DataFrame, tokenizer, labels: list, max_token_len: int = 128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "        self.max_token_len = max_token_len\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        return 0\n",
    "        # TODO: add normalizer / preprocessor logic here / can be implemented as a class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        data_row = self.data.iloc[index]\n",
    "\n",
    "        hate_speech_text = data_row['Text']\n",
    "        labels = data_row[self.labels]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            hate_speech_text,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_token_len,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.FloatTensor(labels)\n",
    "        }\n",
    "    \n",
    "    def _get_stats(self, _print: str = False):\n",
    "        stats = {\n",
    "            \"text_count\": len(self.data),\n",
    "            \"instance_per_label\": self.data[self.labels].sum(),\n",
    "            \"shape\": self.data.shape\n",
    "        }\n",
    "        if (_print): \n",
    "            print(\"\\nDATASET STATISTICS:\\n\")\n",
    "            print(\"Number of Text\", len(self.data))\n",
    "            print(\"Instance per Label\\n\", self.data[self.labels].sum())\n",
    "            print(\"Shape: \", self.data.shape)\n",
    "        return stats\n",
    "\n",
    "    \n",
    "    def _print_sample_hate_speech(self, index: int = 0, get_encoding: bool = False):\n",
    "        sample_row = self.data.iloc[index]\n",
    "        sample_text = sample_row.Text\n",
    "        sample_labels = sample_row[self.labels]\n",
    "        print(\"\\nSAMPLE TRAINING HATE SPEECH:\")\n",
    "        print(\"Index: \", index)\n",
    "        print(\"Text: \", sample_text)\n",
    "        print(\"Labels: \", sample_labels.to_dict())\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sample_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "    \n",
    "        if (get_encoding):\n",
    "            print(\"Encoding:\\n\", encoding, \"\\n\")\n",
    "            print(\"Input IDs: \", encoding[\"input_ids\"].squeeze()[:20])\n",
    "            print(\"Attention Mask: \", encoding[\"attention_mask\"].squeeze()[:20])\n",
    "            print(\"Tokens:\",  self.tokenizer.convert_ids_to_tokens(encoding[\"input_ids\"].squeeze())[:20])\n",
    "\n",
    "    def _get_data_frame(self, _print: str = False):\n",
    "        if (_print): print(self.data)\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLTHSDataModule():\n",
    "    \n",
    "    def __init__(self, train_df, val_df, test_df, labels, tokenizer, batch_size=8, max_token_len=128):\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_len = max_token_len\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.mlths_train_dataset = MLTHSDataset(self.train_df, self.labels, self.tokenizer)\n",
    "        self.mlths_val_dataset = MLTHSDataset(self.val_df, self.labels, self.tokenizer)\n",
    "        self.mlths_test_dataset = MLTHSDataset(self.test_df, self.labels, self.tokenizer)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mlths_train_dataset, batch_size=self.batch_size, num_workers=2, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mlths_val_dataset, batch_size=self.batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mlths_test_dataset, batch_size=self.batch_size, num_workers=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To implement: LINEAR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLTHSClassifier():\n",
    "\n",
    "    def __init__(self, config: dict, labels: list, data_module: MLTHSDataModule):\n",
    "        self.config = config\n",
    "        self.threshold = config['threshold']\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(config['model_name'], return_dict=True)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "\n",
    "        self.data_module = data_module\n",
    "        self.labels = labels\n",
    "\n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.config['lr'], weight_decay=self.config['w_decay'])\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, self.config['n_labels'])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls_embedding = output.last_hidden_state[:, 0, :]\n",
    "        cls_embedding = torch.sigmoid(cls_embedding)\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(\n",
    "                        logits.view(-1, self.config['n_labels']), \n",
    "                        labels.view(-1, self.config['n_labels'])\n",
    "                    )\n",
    "        return loss, logits\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer\n",
    "        total_steps = self.config['train_size'] / self.config['bs']\n",
    "        warmup_steps = math.floor(total_steps * self.config['warmup'])\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "                        optimizer, \n",
    "                        warmup_steps, \n",
    "                        total_steps\n",
    "                    )\n",
    "        return [optimizer], [scheduler]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import MetricCollection, Accuracy, Precision, Recall\n",
    "from transformers import TrainingArguments, Trainer, EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLTHSCTrainer(Trainer):\n",
    "    def __init__(self, config, data_module,*args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.config = config\n",
    "        self.data_module = self.get_data_module()\n",
    "\n",
    "    def get_data_module(self):\n",
    "        mlths_data_module = MLTHSDataModule(\n",
    "        train_df,\n",
    "        val_df,\n",
    "        test_df, \n",
    "        labels=LABELS,\n",
    "        tokenizer=BERT_TOKENIZER,\n",
    "        batch_size=self.config['bs'],\n",
    "        max_token_len=128\n",
    "    )\n",
    "        mlths_data_module.setup()\n",
    "        return mlths_data_module\n",
    "\n",
    "    def get_train_dataloader(self):\n",
    "        return self.data_module.train_dataloader()\n",
    "\n",
    "    def get_eval_dataloader(self):\n",
    "        return self.data_module.val_dataloader()\n",
    "\n",
    "    def get_test_dataloader(self):\n",
    "        return self.data_module.test_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlths_data_module = MLTHSDataModule(\n",
    "        train_df,\n",
    "        val_df,\n",
    "        test_df, \n",
    "        labels=LABELS,\n",
    "        tokenizer=BERT_TOKENIZER,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        max_token_len=128\n",
    "    )\n",
    "\n",
    "mlths_data_module.setup()\n",
    "mlths_dl = mlths_data_module.train_dataloader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model_name': model_name,\n",
    "    'n_labels': len(LABELS),\n",
    "    'train_size': len(mlths_dl),\n",
    "    'bs': BATCH_SIZE,\n",
    "    'n_epochs': N_EPOCHS,\n",
    "    'lr': LEARNING_RATE,\n",
    "    'warmup': 0.2,\n",
    "    'w_decay': 0.01,\n",
    "    'threshold': THRESHOLD\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at gklmip/bert-tagalog-base-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = MLTHSClassifier(config)\n",
    "args = TrainingArguments(\n",
    "    \"checkpoint\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=config['bs'],\n",
    "    per_device_eval_batch_size=config['bs'],\n",
    "    num_train_epochs=config['n_epochs'],\n",
    "    weight_decay=config['w_decay'],\n",
    "    metric_for_best_model=\"f1\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Metrics:\n",
      "Metrics per label:\n",
      "Age:\n",
      "  Precision: 50.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 66.67%\n",
      "Gender:\n",
      "  Precision: 30.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 46.15%\n",
      "Physical:\n",
      "  Precision: 60.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 75.00%\n",
      "Race:\n",
      "  Precision: 50.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 66.67%\n",
      "Religion:\n",
      "  Precision: 50.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 66.67%\n",
      "Others:\n",
      "  Precision: 30.00%\n",
      "  Recall: 100.00%\n",
      "  F1: 46.15%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from transformers import EvalPrediction\n",
    "\n",
    "def multilabel_metrics(predictions, labels, threshold=0.5):\n",
    "\n",
    "    # Apply sigmoid activation to logits/raw scores from the classifier \n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probabilities = sigmoid(torch.Tensor(predictions))\n",
    "\n",
    "    # Filter out labels using the 0.5 threshold\n",
    "    y_pred = np.zeros(probabilities.shape)\n",
    "    y_pred[np.where(probabilities >= threshold)] = 1\n",
    "    \n",
    "    y_true = labels\n",
    "\n",
    "    confusion_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    label_metrics = {}\n",
    "    \n",
    "    classes = ['Age', 'Gender', 'Physical', 'Race', 'Religion', 'Others']\n",
    "\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        TP = confusion_matrix[i, 1, 1]  # True Positives\n",
    "        FP = confusion_matrix[i, 0, 1]  # False Positives\n",
    "        FN = confusion_matrix[i, 1, 0]  # False Negatives\n",
    "        TN = confusion_matrix[i, 0, 0]  # True Negatives\n",
    "\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "        recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        label_name = classes[i]\n",
    "\n",
    "        label_metrics[label_name] = {\n",
    "            \"Precision\": f\"{precision * 100:.2f}%\",\n",
    "            \"Recall\": f\"{recall * 100:.2f}%\",\n",
    "            \"F1-Score\": f\"{f1_score * 100:.2f}%\"\n",
    "        }\n",
    "\n",
    "    # Calculate Hamming Loss\n",
    "    xor_result = np.logical_xor(y_true, y_pred)\n",
    "    xor_sum = np.sum(xor_result)\n",
    "    hamming_loss = xor_sum / (y_true.shape[0] * y_true.shape[1])\n",
    "    \n",
    "    label_metrics['Hamming Loss'] = f\"{hamming_loss:.4f}\"\n",
    "\n",
    "    return label_metrics\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    result = multilabel_metrics(predictions=preds, labels=p.label_ids, threshold=0.5)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MLTHSCTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    tokenizer=BERT_TOKENIZER,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"Multilabel-Tagalog-Hate-Speech-Classifier-Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID                                               Text  Age  Gender  \\\n",
      "0    81  yak tom napaka kadiri neto yak talaga hahaha e...    0       0   \n",
      "1    82  taena haha kung ano ano pang sinasabi tapos li...    0       0   \n",
      "2    83  pukinginang mga chingchong mandurugas kayo coo...    0       0   \n",
      "3    84  PAKYU KAYO ISLAM MGA ISIS ABUSAYAF GAGO LUMAYA...    0       0   \n",
      "4    85  MuKha mo mukhang kabayo magsama kayo ni quibol...    0       0   \n",
      "5    86  Yung 2 teenagers na sinigawan ko Dahil umaawra...    1       1   \n",
      "6    87  TANGINA NI GADGET ADDICT, WALA NANG NAIDULOT K...    0       0   \n",
      "7    88  tangina talaga ng mga straight boys (and girls...    0       1   \n",
      "8    89  Sobrang excited ko na sa mundo kung saan patay...    1       0   \n",
      "9    90  nakakatangina talaga ng mga dating daan. bobo ...    1       1   \n",
      "10   91  pansin nyo ba napakabobo ng mga INC? kakaurat ...    0       0   \n",
      "11   92  Putangina niyo, wala na sana kayong eardrums s...    1       0   \n",
      "12   93  tangina mo lemuel isa kang pakyu mukha kang bayag    0       0   \n",
      "13   94  Like wtf kang chekwa ka! Bastos na Chinese kin...    0       0   \n",
      "14   95  Iba pagka toxic nitong mga baby bra warriors. ...    1       0   \n",
      "15   96                           puta kang bakla ka kupal    0       1   \n",
      "16   97  Girl, shut your stinky pussy nasty goofy old b...    1       1   \n",
      "17   98  Para sa mga \"Millenials\" ðŸ¤£ðŸ¤£ðŸ¤£ O eto daw origin....    1       0   \n",
      "18   99  YALL CATHOLICS BETTER SHUT UR DAMN MOUTHS TALK...    0       0   \n",
      "19  100  putangina may nakita akong kuyang pogi sa time...    0       1   \n",
      "\n",
      "    Physical  Race  Religion  Others  \n",
      "0          0     1         0       0  \n",
      "1          0     0         0       1  \n",
      "2          0     1         0       0  \n",
      "3          0     1         1       0  \n",
      "4          1     0         1       0  \n",
      "5          0     0         0       0  \n",
      "6          0     0         0       1  \n",
      "7          0     0         0       0  \n",
      "8          0     0         0       0  \n",
      "9          1     0         1       0  \n",
      "10         0     0         1       0  \n",
      "11         0     0         0       0  \n",
      "12         1     0         0       0  \n",
      "13         0     1         0       0  \n",
      "14         0     0         0       0  \n",
      "15         0     0         0       0  \n",
      "16         1     0         0       0  \n",
      "17         0     0         0       0  \n",
      "18         0     0         1       0  \n",
      "19         0     0         0       0  \n"
     ]
    }
   ],
   "source": [
    "mlths_train_dataset = MLTHSDataset(train_df, LABELS, BERT_TOKENIZER)\n",
    "mlths_val_dataset = MLTHSDataset(val_df, LABELS, BERT_TOKENIZER)\n",
    "mlths_test_dataset = MLTHSDataset(test_df, LABELS, BERT_TOKENIZER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `MLTHSDataset`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Repo\\Python\\BERT MLTHSC\\main.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Repo/Python/BERT%20MLTHSC/main.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mpredict(mlths_test_dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Repo/Python/BERT%20MLTHSC/main.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions\u001b[39m.\u001b[39mpredictions\u001b[39m.\u001b[39mshape, predictions\u001b[39m.\u001b[39mlabel_ids\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32md:\\Repo\\Python\\BERT MLTHSC\\venv\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:859\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    855\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    856\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`Trainer.predict()` requires a `LightningModule` when it hasn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt been passed in a previous run\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    857\u001b[0m         )\n\u001b[0;32m    858\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 859\u001b[0m     model \u001b[39m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[0;32m    860\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m    861\u001b[0m _verify_strategy_supports_compile(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy)\n",
      "File \u001b[1;32md:\\Repo\\Python\\BERT MLTHSC\\venv\\Lib\\site-packages\\pytorch_lightning\\utilities\\compile.py:131\u001b[0m, in \u001b[0;36m_maybe_unwrap_optimized\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[0;32m    130\u001b[0m _check_mixed_imports(model)\n\u001b[1;32m--> 131\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    132\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(model)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    133\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: `model` must be a `LightningModule` or `torch._dynamo.OptimizedModule`, got `MLTHSDataset`"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(mlths_test_dataset)\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

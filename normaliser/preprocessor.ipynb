{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, pandas as pd, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = os.path.abspath(\"../dataset/mlthsc.csv\")\n",
    "\n",
    "hate_speech = pd.read_csv(df_path, index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity and the removal of inconsistencies in the dataset, we have considered the following criteria in cleaning the dataset before entering the model.\n",
    "1. \tConversion of all texts to lowercase\n",
    "2. \tRemoval of unimportant data (link, emoji, username, punctuation, hashtag, digit)\n",
    "3. \t Removal of unnecessary white spaces in the text\n",
    "4. \tShortening the text into their standard format (eg. “nooooooo” to “no”)\n",
    "5. \tCorrecting misspelled words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'[A-Z]', lambda y: y.group(0).lower(), x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of unimportant links\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'http[s]?://\\S+', '', x))\n",
    "\n",
    "# emoji \n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'[^\\x00-\\x7F]+', '', x))\n",
    "\n",
    "# username\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'@\\w+', '', x))\n",
    "\n",
    "# punctuations\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "# hashtag\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'#', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of unnecessary white spaces\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shortening the text into their standard format\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: re.sub(r'(\\w)(\\1{2,})', r'\\1', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Corrector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the spelling of misspelled words in every hate speech text\n",
    "\n",
    "# Load spelling corrector model\n",
    "with open('../model/spellchecker_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the loaded model to correct the spelling\n",
    "hate_speech['Text'] = hate_speech['Text'].apply(lambda x: ' '.join([loaded_model.correction(word) for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV file\n",
    "hate_speech.to_csv('../dataset/cleaned_mlthsc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

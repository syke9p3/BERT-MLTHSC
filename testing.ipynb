{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, EvalPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"model-trial-1\"\n",
    "trained_model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gklmip/bert-tagalog-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"Age\", \"Gender\", \"Physical\", \"Race\", \"Religion\", \"Others\"]\n",
    "id2label = {idx:label for idx, label in enumerate(LABELS)}\n",
    "label2id = {label:idx for idx, label in enumerate(LABELS)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./dataset/cleaned_mlthsc.csv', nrows=1000)\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# We will use only the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text into BERT representations\n",
    "\n",
    "def encode_data(data):\n",
    "    text = data[\"Text\"]\n",
    "\n",
    "    encoding = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            return_tensors='pt',\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=128,\n",
    "            return_token_type_ids=False,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "    \n",
    "    labels = data[LABELS]\n",
    "    \n",
    "    representation = {\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'labels': torch.FloatTensor(labels)\n",
    "    }\n",
    "\n",
    "    return representation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create encoded testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of encoded examples for test data\n",
    "encoded_test_data = [encode_data(row) for _, row in test_data.iterrows()]\n",
    "\n",
    "# Combine the encoded examples into a dictionary\n",
    "encoded_test_dict = {key: [example[key] for example in encoded_test_data] for key in encoded_test_data[0]}\n",
    "\n",
    "# Convert the dictionaries to datasets\n",
    "test_dataset = Dataset.from_dict(encoded_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'labels'],\n",
      "    num_rows: 200\n",
      "})\n",
      "{'input_ids': [101, 18215, 6067, 1116, 28888, 3591, 1863, 3587, 32560, 1738, 14683, 1744, 1894, 12936, 19451, 1741, 5397, 2309, 1111, 1894, 3407, 51114, 1894, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Print the first few examples to verify the encoding\n",
    "print(test_dataset)\n",
    "print(test_dataset[0])\n",
    "print(test_dataset[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 1.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = test_dataset['labels']\n",
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[1. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 1. 0. 0.]\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 1. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 1., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 1., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([1., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 1., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 1., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([0., 1., 0., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([1., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 1., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 1., 0., 0.]),\n",
       " array([0., 0., 0., 1., 1., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 1., 0., 0.]),\n",
       " array([1., 0., 0., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0.]),\n",
       " array([0., 1., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = [] # list of lists of predictions\n",
    "\n",
    "for text in test_data['Text']:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_outputs = trained_model(**preprocess_text(text))\n",
    "\n",
    "    probabilities = np.array(model_outputs.logits.sigmoid().tolist()[0])\n",
    "    \n",
    "    prediction = np.zeros(len(probabilities))\n",
    "    prediction[np.where(probabilities >= 0.5)] = 1\n",
    "\n",
    "    print(prediction)\n",
    "\n",
    "    y_pred.append(prediction)\n",
    "\n",
    "y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_metrics(logits, labels, threshold=0.5):\n",
    "\n",
    "    print(\"predictions:\", logits)\n",
    "\n",
    "    # Apply sigmoid activation to logits/raw scores from the classifier \n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probabilities = sigmoid(torch.Tensor(logits))\n",
    "\n",
    "    print(\"probabilities:\", probabilities)\n",
    "\n",
    "    # Set labels as 0 or 1 with 0.5 threshold\n",
    "    y_pred = np.zeros(probabilities.shape)                  # Create an array of 0s with size: number of labels (six)\n",
    "    y_pred[np.where(probabilities >= threshold)] = 1        # Set each label to 1 only if logit is greater than threshold (0.5) \n",
    "\n",
    "    y_true = np.zeros(labels.shape)\n",
    "    y_true[np.where(labels == 1)] = 1\n",
    "\n",
    "    print(\"Y PRED:\", y_pred)\n",
    "    print(\"Y TRUE:\", y_true)\n",
    "    \n",
    "    confusion_matrix = multilabel_confusion_matrix(y_true, y_pred)\n",
    "    print(confusion_matrix)\n",
    "    label_metrics = {}\n",
    "    \n",
    "    classes = ['Age', 'Gender', 'Physical', 'Race', 'Religion', 'Others']\n",
    "\n",
    "    for i in range(confusion_matrix.shape[0]):\n",
    "        TP = confusion_matrix[i, 1, 1]  # True Positives\n",
    "        FP = confusion_matrix[i, 0, 1]  # False Positives\n",
    "        FN = confusion_matrix[i, 1, 0]  # False Negatives\n",
    "        TN = confusion_matrix[i, 0, 0]  # True Negatives\n",
    "\n",
    "        # TN FP\n",
    "        # FN TP \n",
    "\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "        recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "        label_name = classes[i]\n",
    "\n",
    "        label_metrics[label_name] = {\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1-Score\": f1_score\n",
    "        }\n",
    "\n",
    "    # Calculate Hamming Loss\n",
    "    xor_result = np.logical_xor(y_true, y_pred)\n",
    "    xor_sum = np.sum(xor_result)\n",
    "    hamming_loss = xor_sum / (y_true.shape[0] * y_true.shape[1])\n",
    "    \n",
    "    label_metrics['Hamming Loss'] = hamming_loss\n",
    "\n",
    "    return label_metrics\n",
    "\n",
    "def compute_metrics():\n",
    "    preds = get_predictions()\n",
    "\n",
    "    print(\"preds\", preds)\n",
    "\n",
    "    result = multilabel_metrics(predictions=preds, labels=p.label_ids, threshold=0.5)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    encoding = tokenizer(text, padding=\"max_length\", truncation=True, max_length=128, return_tensors='pt')\n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_pred(test_sentence):\n",
    "\n",
    "    encoded_test_sentence = preprocess_text(test_sentence)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_outputs = trained_model(**encoded_test_sentence)\n",
    "\n",
    "    predictions = model_outputs.logits.sigmoid().tolist()[0]  # Apply sigmoid to get probabilities\n",
    "\n",
    "    # Get all labels\n",
    "    label_probabilities = [{\"name\": label, \"probability\": f\"{prob * 100:.2f}%\"} for label, prob in zip(LABELS, predictions)]\n",
    "\n",
    "    # Sort label probabilities in descending order\n",
    "    label_probabilities = sorted(label_probabilities, key=lambda item: -float(item[\"probability\"][:-1]))\n",
    "    print(label_probabilities)\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    # Labels greater than 0.5 threshold\n",
    "    predicted_labels = [(label, f\"{pred*100:.2f}%\") for label, pred in zip(LABELS, predictions) if pred >= threshold]\n",
    "    print(\"Input:\", test_sentence)\n",
    "    print(\"Probabilities: \", label_probabilities)\n",
    "\n",
    "    print(\"Labels:\")\n",
    "    for label, probability in predicted_labels:\n",
    "        print(f\"({label}, {probability})\")\n",
    "\n",
    "\n",
    "    return label_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "csv_file = \"result.csv\"\n",
    "\n",
    "header = [\"ID\", \"Text\", \"Age\", \"Gender\", \"Physical\", \"Race\", \"Religion\", \"Others\"]\n",
    "\n",
    "with open(csv_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "\n",
    "def evaluate_dataset(dataset):\n",
    "\n",
    "    token_id = 1\n",
    "\n",
    "    with open(dataset, 'r') as f:\n",
    "        tagged_sentences = f.readlines()\n",
    "\n",
    "    for text in tagged_sentences: \n",
    "    \n",
    "        sentence = preprocess_sentence(tagged_sentence)\n",
    "        sentence = sentence.split()\n",
    "\n",
    "        y_pred_labels = get_predicted_tags(tagged_sentence)\n",
    "        y_true_labels = get_actual_tags(tagged_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Goals:** \n",
    "- Get the y_pred which is a list of predictions for all 1000 rows \n",
    "- Get the y_true which is a list of true labels for all 1000 rows \n",
    "\n",
    "**Pseudocode:** \n",
    "- For each row in dataset\n",
    "    - Get the encpded\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
